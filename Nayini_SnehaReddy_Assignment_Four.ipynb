{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "1. Features (text representation) used for topic modeling.\n",
        "\n",
        "2. Top 10 clusters for topic modeling.\n",
        "\n",
        "3. Summarize and describe the topic for each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuFPKhC0m1fd",
        "outputId": "44eb7005-913b-43c7-d41e-69caa5fb4462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "movie, br, just, film, time, like, really, bad, good, movies\n",
            "\n",
            "\n",
            "Topic 1:\n",
            "br, film, story, just, best, time, movie, old, like, characters\n",
            "\n",
            "\n",
            "Topic 2:\n",
            "br, movie, film, think, like, work, way, really, actually, great\n",
            "\n",
            "\n",
            "Topic 3:\n",
            "br, movie, film, like, bad, good, know, just, great, really\n",
            "\n",
            "\n",
            "Topic 4:\n",
            "br, movie, film, like, just, good, really, time, bad, story\n",
            "\n",
            "\n",
            "Topic 5:\n",
            "film, br, movie, like, just, good, story, characters, disney, really\n",
            "\n",
            "\n",
            "Topic 6:\n",
            "film, br, movie, like, just, good, think, story, films, make\n",
            "\n",
            "\n",
            "Topic 7:\n",
            "br, film, movie, just, like, good, little, time, story, people\n",
            "\n",
            "\n",
            "Topic 8:\n",
            "br, movie, just, like, game, don, good, story, film, people\n",
            "\n",
            "\n",
            "Topic 9:\n",
            "br, movie, film, great, story, like, acting, movies, little, really\n",
            "\n",
            "\n",
            "Cluster 0:\n",
            "Top terms: movie, br, just, film, time, like, really, bad, good, movies\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 1:\n",
            "Top terms: br, film, story, just, best, time, movie, old, like, characters\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 2:\n",
            "Top terms: br, movie, film, think, like, work, way, really, actually, great\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 3:\n",
            "Top terms: br, movie, film, like, bad, good, know, just, great, really\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 4:\n",
            "Top terms: br, movie, film, like, just, good, really, time, bad, story\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 5:\n",
            "Top terms: film, br, movie, like, just, good, story, characters, disney, really\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 6:\n",
            "Top terms: film, br, movie, like, just, good, think, story, films, make\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 7:\n",
            "Top terms: br, film, movie, just, like, good, little, time, story, people\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 8:\n",
            "Top terms: br, movie, just, like, game, don, good, story, film, people\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n",
            "Cluster 9:\n",
            "Top terms: br, movie, film, great, story, like, acting, movies, little, really\n",
            "Description: Write your description based on these terms.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models import LdaModel\n",
        "import gensim.matutils\n",
        "\n",
        "# Load your dataset (assuming it's in a CSV format)\n",
        "data = pd.read_csv('/content/INFO 5731_DATA_SET_ASSIGN_4.csv')\n",
        "\n",
        "# Assuming your dataset has a column 'text' containing the text data\n",
        "documents = data['clean_text'].tolist()\n",
        "\n",
        "# Preprocess the text data (tokenization, stop word removal, etc.)\n",
        "# This can be done using libraries like NLTK or spaCy\n",
        "\n",
        "# Create a bag of words representation of the documents\n",
        "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the sparse matrix into a Gensim corpus\n",
        "corpus = gensim.matutils.Sparse2Corpus(X.T)\n",
        "\n",
        "# Create a dictionary mapping id to word\n",
        "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
        "\n",
        "# Build the LDA model\n",
        "num_topics = 10\n",
        "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, passes=10)\n",
        "\n",
        "# Print the top 10 clusters for topic modeling\n",
        "for topic_idx, topic in lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False):\n",
        "    print(f\"Topic {topic_idx}:\")\n",
        "    topic_terms = [term for term, _ in topic]\n",
        "    print(\", \".join(topic_terms))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Summarize and describe the topic for each cluster\n",
        "for topic_idx, topic in lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False):\n",
        "    print(f\"Cluster {topic_idx}:\")\n",
        "    topic_terms = [term for term, _ in topic]\n",
        "    print(\"Top terms:\", \", \".join(topic_terms))\n",
        "    print(\"Description: Write your description based on these terms.\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "1. Select features for the sentiment classification and explain why you select these features. Use a markdown cell to provide your explanation.\n",
        "\n",
        "2. Select two of the supervised learning algorithms/models from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build two sentiment classifiers respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "3. Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. The test set must be used for model evaluation in this step. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "7210f421-4b9c-4878-deda-947ff058228a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Cross-Validation Scores: [0.8     0.78125 0.80625 0.8     0.78125]\n",
            "Mean Accuracy (SVM): 0.79375\n",
            "Random Forest Cross-Validation Scores: [0.75625 0.8     0.7875  0.75625 0.73125]\n",
            "Mean Accuracy (Random Forest): 0.76625\n",
            "SVM Test Accuracy: 0.815\n",
            "SVM Test Precision: 0.8150618028338861\n",
            "SVM Test Recall: 0.815\n",
            "SVM Test F1 Score: 0.8148469119085233\n",
            "Random Forest Test Accuracy: 0.755\n",
            "Random Forest Test Precision: 0.7570537084398977\n",
            "Random Forest Test Recall: 0.755\n",
            "Random Forest Test F1 Score: 0.7537082166553142\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/INFO 5731_DATA_SET_ASSIGN_4.csv')\n",
        "\n",
        "# dataset has columns 'clean_text' (feature) and 'sentiment' (target)\n",
        "X = data['clean_text']\n",
        "y = data['sentiment']\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Define classifiers\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Cross-validation (5-fold)\n",
        "def evaluate_classifier(classifier, X_train, y_train):\n",
        "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    return cv_scores\n",
        "\n",
        "# Evaluate SVM classifier\n",
        "svm_cv_scores = evaluate_classifier(svm_classifier, X_train_tfidf, y_train)\n",
        "print(\"SVM Cross-Validation Scores:\", svm_cv_scores)\n",
        "print(\"Mean Accuracy (SVM):\", svm_cv_scores.mean())\n",
        "\n",
        "# Evaluate Random Forest classifier\n",
        "rf_cv_scores = evaluate_classifier(rf_classifier, X_train_tfidf, y_train)\n",
        "print(\"Random Forest Cross-Validation Scores:\", rf_cv_scores)\n",
        "print(\"Mean Accuracy (Random Forest):\", rf_cv_scores.mean())\n",
        "\n",
        "# Train and evaluate classifiers on the test set\n",
        "def evaluate_test_set(classifier, X_train, y_train, X_test, y_test):\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate SVM classifier on test set\n",
        "svm_accuracy, svm_precision, svm_recall, svm_f1 = evaluate_test_set(svm_classifier, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
        "print(\"SVM Test Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Test Precision:\", svm_precision)\n",
        "print(\"SVM Test Recall:\", svm_recall)\n",
        "print(\"SVM Test F1 Score:\", svm_f1)\n",
        "\n",
        "# Evaluate Random Forest classifier on test set\n",
        "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_test_set(rf_classifier, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
        "print(\"Random Forest Test Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Test Precision:\", rf_precision)\n",
        "print(\"Random Forest Test Recall:\", rf_recall)\n",
        "print(\"Random Forest Test F1 Score:\", rf_f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(20 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n",
        "\n",
        "1. Conduct necessary Explatory Data Analysis (EDA) and data cleaning steps on the given dataset. Split data for training and testing.\n",
        "2. Based on the EDA results, select a number of features for the regression model. Shortly explain why you select those features.\n",
        "3. Develop a regression model. The train set should be used.\n",
        "4. Evaluate performance of the regression model you developed using appropriate evaluation metrics. The test set should be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJLVQTIc2wvh"
      },
      "source": [
        "1.Conduct necessary Explatory Data Analysis (EDA) and data cleaning steps on the given dataset. Split data for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfvMKJjIXS5G",
        "outputId": "a1a12c16-2c43-4000-b834-200d8e78090d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     588 non-null    object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n",
            "None\n",
            "Id               0\n",
            "MSSubClass       0\n",
            "MSZoning         0\n",
            "LotFrontage      0\n",
            "LotArea          0\n",
            "                ..\n",
            "MoSold           0\n",
            "YrSold           0\n",
            "SaleType         0\n",
            "SaleCondition    0\n",
            "SalePrice        0\n",
            "Length: 81, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the training dataset\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(data.head())  # View the first few rows\n",
        "print(data.info())  # Display information about columns and data types\n",
        "\n",
        "# Identify numeric columns for imputation\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Fill missing values in numeric columns with mean\n",
        "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
        "\n",
        "# Verify that there are no more missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = data.drop('SalePrice', axis=1)  # Features\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now X_train, y_train are the training data and labels\n",
        "# X_test, y_test are the testing data and labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaKoE5Uf4POQ",
        "outputId": "c7cc8793-b98d-41e5-c886-338ec1c176b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training RMSE: 37970.210024760556\n",
            "Testing RMSE: 39763.295265780616\n",
            "Feature Coefficients:\n",
            "OverallQual: 20392.513001014442\n",
            "GrLivArea: 48.80980118759696\n",
            "GarageCars: 15144.237203506369\n",
            "TotalBsmtSF: 25.36531866067783\n",
            "YearBuilt: 315.92335034468454\n"
          ]
        }
      ],
      "source": [
        "#Based on the EDA results, select a number of features for the regression model. Shortly explain why you select those features.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Select relevant features and target variable\n",
        "selected_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt']\n",
        "X = data[selected_features]\n",
        "y = data['SalePrice']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
        "\n",
        "print(f\"Training RMSE: {train_rmse}\")\n",
        "print(f\"Testing RMSE: {test_rmse}\")\n",
        "\n",
        "# Print coefficients to understand feature importance\n",
        "print(\"Feature Coefficients:\")\n",
        "for feature, coef in zip(selected_features, model.coef_):\n",
        "    print(f\"{feature}: {coef}\")\n",
        "\n",
        "# Explanation for feature selection:\n",
        "# 1. OverallQual: Quality rating impacts perceived value and market appeal.\n",
        "# 2. GrLivArea: Above ground living area correlates strongly with house size and price.\n",
        "# 3. GarageCars: Larger garages indicate higher capacity and often accompany higher-priced homes.\n",
        "# 4. TotalBsmtSF: Basement area contributes significantly to overall square footage and value.\n",
        "# 5. YearBuilt: Age of the house can influence desirability and maintenance costs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooPYIsFp5JmF",
        "outputId": "bf2a1a4d-1359-4fb5-d974-5d6754d39bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training RMSE: 38254.68965518844\n",
            "Model Coefficients:\n",
            "OverallQual: 20391.140933744067\n",
            "GrLivArea: 50.83150559496018\n",
            "GarageCars: 14510.003299796621\n",
            "TotalBsmtSF: 29.97787731828509\n",
            "YearBuilt: 301.43341058974954\n"
          ]
        }
      ],
      "source": [
        "#Develop a regression model. The train set should be used.\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Select relevant features and target variable\n",
        "selected_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt']\n",
        "X_train = data[selected_features]\n",
        "y_train = data['SalePrice']\n",
        "\n",
        "# Build a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict house prices on the training set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the training set using RMSE\n",
        "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "print(f\"Training RMSE: {train_rmse}\")\n",
        "\n",
        "# Optionally, print the model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "for feature, coef in zip(selected_features, model.coef_):\n",
        "    print(f\"{feature}: {coef}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofjaxc6S5lM1",
        "outputId": "c462ee5a-1f58-4bf1-a139-a8d99efd7c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE: 191831.25716474172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Evaluate performance of the regression model you developed using appropriate evaluation metrics. The test set should be used.\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Select relevant features and target variable for the test set\n",
        "selected_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt']\n",
        "X_test = test_data[selected_features]\n",
        "\n",
        "# Identify the appropriate target variable from your dataset\n",
        "# Replace 'Your_Target_Variable' with the actual name of the target variable\n",
        "target_variable = 'SaleCondition'\n",
        "y_test = test_data[target_variable]\n",
        "\n",
        "# Encode categorical target variable into numerical format (Label Encoding)\n",
        "label_encoder = LabelEncoder()\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "\n",
        "# Handle missing values in the test set (if any)\n",
        "# Use SimpleImputer to replace missing values in numerical features with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_test_imputed = imputer.fit_transform(X_test)\n",
        "\n",
        "# Use the trained model to make predictions on the test set\n",
        "y_test_pred = model.predict(X_test_imputed)\n",
        "\n",
        "# Evaluate the model performance on the test set using RMSE\n",
        "test_rmse = mean_squared_error(y_test_encoded, y_test_pred, squared=False)\n",
        "print(f\"Test RMSE: {test_rmse}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIeV5zRs9Qgw"
      },
      "source": [
        "The Test data does not contain the target variable 'SalePrice'. I used target variable as 'SaleCondition'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BbswDvnEX-k"
      },
      "source": [
        "# **Question 4: Using Pre-trained LLMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKwKTnW1EX-k"
      },
      "source": [
        "(20 points)\n",
        "Utilize a **Pre-trained Language Model (PLM) from the Hugging Face Repository** for predicting sentiment polarities on the data you collected in Assignment 3.\n",
        "\n",
        "Then, choose a relevant LLM from their repository, such as GPT-3, BERT, or RoBERTa or any other related models.\n",
        "1. (5 points) Provide a brief description of the PLM you selected, including its original pretraining data sources,  number of parameters, and any task-specific fine-tuning if applied.\n",
        "2. (10 points) Use the selected PLM to perform the sentiment analysis on the data collected in Assignment 3. Only use the model in the **zero-shot** setting, NO finetuning is required. Evaluate performance of the model by comparing with the groundtruths (labels you annotated) on Accuracy, Precision, Recall, and F1 metrics.\n",
        "3. (5 points) Discuss the advantages and disadvantages of the selected PLM, and any challenges encountered during the implementation. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Description of the Selected PLM: BERT (Bidirectional Encoder Representations from Transformers)\n",
        "Original Sources of Pretraining Data: A sizable corpus of literature from BooksCorpus (800 million words) and the English Wikipedia (2.5 billion words) was used to pretrain BERT. For pretraining, it makes use of the Next Sentence Prediction (NSP) and Masked Language Modelling (MLM) tasks.\n",
        "The quantity of parameters Larger variants, such as BERT-large, include 340 million parameters, compared to 110 million in BERT-base.\n",
        "Task-Dependent Adjustment: BERT can be optimised for sentiment analysis using sentiment-specific datasets such as Twitter sentiment datasets, Yelp reviews, and IMDb ratings. But we'll use BERT in a zero-shot configuration without any fine-tuning for this purpose."
      ],
      "metadata": {
        "id": "oB2F861jHcto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJgHWnOhFm-C",
        "outputId": "384961da-e545-4282-ee7a-a5ea25c09379"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.004\n",
            "Precision: 0.11133333333333333\n",
            "Recall: 0.003999999999999999\n",
            "F1 Score: 0.007722543352601155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import pipeline\n",
        "import textwrap\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/INFO 5731_DATA_SET_ASSIGN_4.csv')\n",
        "\n",
        "# Assuming your dataset has columns 'clean_text' (feature) and 'sentiment' (target)\n",
        "texts = data['clean_text'].tolist()\n",
        "labels = data['sentiment'].tolist()\n",
        "\n",
        "# Initialize sentiment analysis pipeline with BERT in zero-shot classification mode\n",
        "sentiment_classifier = pipeline(\"zero-shot-classification\", model=\"distilbert-base-uncased\")\n",
        "\n",
        "# Specify possible labels for sentiment (positive, negative, neutral)\n",
        "possible_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Define a function to preprocess text to fit within the maximum sequence length of BERT\n",
        "def preprocess_text(text):\n",
        "    # Use textwrap to wrap long text and take the first part (to fit within BERT's max sequence length)\n",
        "    wrapped_text = textwrap.fill(text, width=512, break_long_words=False)\n",
        "    return wrapped_text.split('\\n')[0]  # Take the first line (to ensure it's within BERT's max length)\n",
        "\n",
        "# Preprocess texts to fit within BERT's max sequence length\n",
        "prepared_texts = [preprocess_text(text) for text in texts]\n",
        "\n",
        "# Perform zero-shot sentiment analysis using BERT\n",
        "predictions = [sentiment_classifier(text, candidate_labels=possible_labels)['labels'][0] for text in prepared_texts]\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "precision = precision_score(labels, predictions, average='weighted', labels=possible_labels)\n",
        "recall = recall_score(labels, predictions, average='weighted', labels=possible_labels)\n",
        "f1 = f1_score(labels, predictions, average='weighted', labels=possible_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Advantages and Disadvantages of BERT for Sentiment Analysis\n",
        "Advantages:\n",
        "\n",
        "Because of its bidirectional nature and self-attention mechanism, BERT is able to record intricate linguistic patterns and context.\n",
        "BERT may generalise to new tasks without requiring task-specific fine-tuning thanks to zero-shot learning.\n",
        "Sentiment analysis in several languages is made possible by multilingual capabilities.\n",
        "Drawbacks:\n",
        "\n",
        "BERT can be costly to compute and needs a lot of resources for inference.\n",
        "restricted interpretability in contrast to more established machine learning models such as logistic regression or SVM.\n",
        "When dealing with noisy or out-of-domain data, BERT's performance may suffer.\n",
        "\n",
        "Challenges Encountered:\n",
        "\n",
        "Selecting the best BERT model for the job at hand and being aware of its input and output formats.\n",
        "Using BERT's zero-shot method to multiclass sentiment analysis, particularly in cases of imbalanced classes.\n",
        "controlling the amount of memory used and the time it takes for inference, particularly when working with big datasets or deploying in situations with limited resources.\n",
        "BERT uses extensive text corpora for pretraining, resulting in state-of-the-art performance for sentiment analysis tasks overall. To obtain optimal performance, however, careful consideration of computational resources, job needs, and model setups must be made when using it."
      ],
      "metadata": {
        "id": "Ixqj3vneICDP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}